---
title: Using Leader-Follower Topology for Availability
owner: MySQL
---

You can maintain availability of your MySQL databases by keeping two copies of your database,
one on a leader (master) instance and another on a follower (slave) instance.
If the leader instance fails due to hardware or software issues or during a period of planned maintenance,
you can initiate a failover to the follower instance.
This helps minimize downtime for apps that bind to your MySQL databases.

For more information, see:

* [About Leader-Follower](./about-leader-follower.html) 
* [Events that Interrupt Service](./interruptions.html)

## <a id="process"></a> Leader-Follower Setup and Failover Process

The following are the high-level steps for setting up and using a leader-follower topology, and for doing a failover.

### Leader-Follower Setup

1. The operator configures a leader-follower plan.
   See [Configure a Leader-Follower Service Plan](#config-plan) below.

1. Developers create an instance from the leader-follower plan.
   Doing this automatically deploys two MySQL VMs in a leader-follower topology.
   See [Create a Service Instance](./use.html#create).

1. Developers bind apps to the leader in the leader-follower plan instance, using the leader's IP address.
   Data is written to the leader and asynchronously replicated on the follower.
   See [Bind a Service Instance to Your App](./use.html#bind).

### Failover Process 

1. If the leader instance fails, the operator manually triggers a failover,
   so the working instance (follower) becomes the new leader. See [Trigger a Failover](#failover) below.

1. After a failover, the developer unbinds the app from the leader-follower plan and then binds it again to use the new leader.
   See [Unbind an App from a Service Instance](./use.html#unbind).


## <a id="config-plan"></a> Configure a Leader-Follower Service Plan

You can configure up to five leader-follower service plans.

After you configure the leader-follower plan, it is available in the Marketplace.
When a developer creates a leader-follower service instance,
a leader VM is automatically deployed in one availability zone (AZ),
and a follower VM is deployed in another AZ.

To configure a leader-follower service plan, do the following:

1. Follow the steps for [configuring an active service plan](install-config.html#active),
   and do the following specifically for the leader-follower plan:
	1. Click the tab for any of the five available service plans: Plan 1 to Plan 5.
	1. Select the **Multi-node deployment** checkbox.
		![multi node checkbox](multi-node-box.png)
	1. Select a **MySQL VM Type** and a **MySQL Persistent Disk**.
	1. Select two **MySQL Availability Zones** to use for the MySQL VMs.
	1. Click **Save**.
1. In the Ops Manager Installation Dashboard, click **Apply Changes**.

## <a id="monitor"></a> Monitor Leader-Follower Instances

In order to decide if a failover is needed, you must monitor leader-follower instances.

In monitoring the leader-follower VMs, pay attention to the following metrics:

* `/p.mysql/available`: This metric records whether the MySQL VMs are responding to requests. 
Values are either 1 (available) or 0 (not available).

* `/p.mysql/follower_seconds_since_leader_heartbeat`: Whenever the leader VM emits a heartbeat,
  the heartbeat is written to the leader database and replicated to the follower.
  This metric measures the number of seconds that elapses between the leader heartbeat
  and the replication of the heartbeat in the follower database,
  so you can determine how far behind the follower is from the leader. 
  Normal values for this metric depend on your apps.

* `/p.mysql/follower_seconds_behind_master`: The follower VM copies database writes from the leader VM,
  but takes time to apply them to its own database. 
  This metric measures how far behind the follower VM is in applying these writes. 
  For example, a follower VM may have copied writes from the leader VM that are timestamped up to 4:00pm,
  but it has only applied writes up to 1:00pm. Normal values for this metric depend on your apps.

For more information, see [KPIs for MySQL Service Instances](monitor.html#kpi4MySQL) in <em>Monitoring and KPIs</em>.

## <a id="errands"></a> Errands Used in Leader-Follower Failover

This section describes the errands used in the [Trigger a Failover](#failover) procedures below. 
You can also use these errands to create custom failover scripts. 
 
Operators use the BOSH CLI v2 to run the errands on the deployment for a particular leader-follower service instance.

The errands used in the failover procedures are:

* **configure-leader-follower**: 
  * Configures replication on the follower and ensures the leader is writable
  * Runs after every create or update of a leader-follower instance
  * Fails and alerts operators, via BOSH errand output, if the service instance is in a bad state

* **make-read-only**: 
  * Demotes a leader VM to a follower
  * Sets the VM to read-only, and guarantees that apps no longer write to this VM
  * Relays all in-flight transactions on this former leader VM to the follower VM, if it is accessible

* **make-leader**: 
  * Promotes a follower VM to a leader
  * Removes replication configuration from the VM, waits for all transactions to be applied to the VM,
    and sets the VM as writable
  * Fails if the original leader is still writeable to protect against data divergence


## <a id="failover"></a> Trigger a Failover

You may want to trigger a failover to the follower VM in the following scenarios:

* The leader VM fails
* The performance of the leader VM degrades
* You want to take the leader VM down to do planned maintenance 

There are two different scenarios for triggering a failover:

[**Scenario 1**](#no-access): You no longer have access to the leader VM.   
  To trigger a failover if you cannot access the leader VM, follow these procedures:

+ [Retrieve Information](#retrieve)
+ [Promote the Follower](#promote) 


[**Scenario 2**](#access): You still have access to the leader VM.  
  To trigger a failover when you can access the leader VM, follow these procedures:

+ [Retrieve Information](#retrieve-2)
+ [Promote the Follower](#promote-2) 
+ [Clean Up Former Leader VM](#clean-up)

### <a id="no-access"></a> Scenario 1: You No Longer Have Access to the Leader VM

If you cannot access the leader VM, do the following procedures to trigger a failover.

#### <a id='retrieve'></a> Retrieve Information

Perform the following steps to retrieve the information necessary
for stopping the leader and promoting the follower: 

1. Target the Cloud Controller of your PCF deployment with the Cloud Foundry Command Line Interface (cf CLI).
   For example:
  <pre class="terminal">$ cf api api.pcf.example.com</pre>
1. Log in:
  <pre><code>cf login</code></pre>
1. Enter the org and space where the leader-follower service instance is located.
1. Retrieve the GUID of the service instance by running the following command:
    <pre><code>cf service SERVICE-INSTANCE --guid</code></pre>
    <br>
    Where `SERVICE-INSTANCE` is the name of the leader-follower service instance. 
  <br><br>
  For example:
  <pre class="terminal">$ cf service my-lf-instance --guid
  82ddc607-710a-404e-b1b8-a7e3ea7ec063
  </pre>
  If you do not know the name of the service instance, you can list service instances in the space with `cf services`.
1. Perform the steps in [Gather Credential and IP Address Information](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#gather)
   and [SSH into Ops Manager](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#ssh) of
   <em>Advanced Troubleshooting with the BOSH CLI</em> to SSH into the Ops Manager VM.
1. From the Ops Manager VM, log in to your BOSH Director with the BOSH CLI v2.
   See [Log in to the BOSH Director](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#log-in) in
   <em>Advanced Troubleshooting with the BOSH CLI</em>.
1. Use the BOSH CLI v2 to run the `inspect` errand with the following command:
  <pre><code>bosh2 -d service-instance\_GUID run-errand inspect</code></pre>
  <br>
  Where `GUID` is the GUID of the leader-follower service instance retrieved above.
  <br><br>
  For example:
  <pre class="terminal">
  $ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 \
      run-errand inspect
  </pre>
1. Examine the output and locate the information about the leader-follower MySQL VMs:
  <pre class="terminal">
  Instance   mysql/37e4b6bc-2ed6-4bd2-84d1-e59a91f5e7f8
  Exit Code  0
  Stdout     -
  Stderr     2017/12/13 22:26:56 Started executing command: inspect
             2017/12/13 22:26:56 Started GET http<span>s:</span>//127.0.0.1:8443/status
             2017/12/13 22:26:56
             Has Data: true
             Read Only: true
             GTID Executed: 524c4be4-d540-11e7-a1d2-42010a000805:1-85297
             Replication Configured: true
  Instance   mysql/ca0ed8b5-7590-4cde-bba8-7ca2935f2bd0
  Exit Code  0
  Stdout     -
  Stderr     2017/12/13 22:26:56 Started executing command: inspect
             2017/12/13 22:26:56 Started GET http<span>s:</span>//127.0.0.1:8443/status
             2017/12/13 22:26:57
             Has Data: true
             Read Only: false
             GTID Executed: 524c4be4-d540-11e7-a1d2-42010a000805:1-85298
             Replication Configured: false
  </pre>
1. Identify the instance marked `Read Only: false`.
   This is the leader VM.
   Record the index, which is the value for `Instance` after `mysql/`.
   In the above output, the index of the leader VM is `ca0ed8b5-7590-4cde-bba8-7ca2935f2bd0`.
1. Record the index of the other instance, which is the follower VM.
   In the above output, the index of the follower VM is `37e4b6bc-2ed6-4bd2-84d1-e59a91f5e7f8`.


#### <a id='promote'></a> Promote the Follower

Perform the following steps to stop the leader VM and promote the follower VM to the new leader:

1. Stop the leader VM, using the same values as above.
   For example:
   <pre class="terminal">
    $ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 \
      stop mysql/ca0ed8b5-7590-4cde-bba8-7ca2935f2bd0</pre>
1. Set the follower VM as writable, using the index of the follower VM retrieved above.
   For example:
   <pre class="terminal">
    $ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 \
      run-errand make-leader \
      --instance=mysql/37e4b6bc-2ed6-4bd2-84d1-e59a91f5e7f8
   </pre>
   If this command returns an error, re-run it until the follower VM has completed applying the transactions. 
1. Unbind the app from the leader-follower service instance.
   Run the following command:
   <pre><code>cf unbind-service APP SERVICE-INSTANCE</code></pre>
   <br>
   Where:
   <ul><li>`APP`: This is the name of the app bound to the leader-follower service instance.</li>
   <li>`SERVICE-INSTANCE`: This is the name of the leader-follower service instance.</li></ul>
   For example:
   <pre class="terminal">
   $ cf unbind-service my-app my-lf-instance
   </pre>
1. Rebind the app to the leader-follower service instance, using the same values as above.
   For example:
   <pre class="terminal">
   $ cf bind-service my-app my-lf-instance
   </pre>
1. Restage the app.
   For example:
   <pre class="terminal">
   $ cf restage my-app
   </pre>

### <a id="access"></a> Scenario 2: You Still Have Access to the Leader VM

If you can access the leader VM, do the following procedures to trigger a failover.

#### <a id='retrieve-2'></a> Retrieve Information

Perform the following steps to retrieve the information necessary
for stopping the leader and promoting the follower: 

1. Target the Cloud Controller of your PCF deployment with the Cloud Foundry Command Line Interface (cf CLI).
   For example:
  <pre class="terminal">$ cf api api.pcf.example.com</pre>
1. Log in:
  <pre><code>cf login</code></pre>
1. Enter the org and space where the leader-follower service instance is located.
1. Retrieve the GUID of the service instance by running the following command:
    <pre><code>cf service SERVICE-INSTANCE --guid</code></pre>
    <br>
    Where `SERVICE-INSTANCE` is the name of the leader-follower service instance. 
  <br><br>
  For example:
  <pre class="terminal">$ cf service my-lf-instance --guid
  82ddc607-710a-404e-b1b8-a7e3ea7ec063
  </pre>
  If you do not know the name of the service instance, you can list service instances in the space with `cf services`.
1. Perform the steps in [Gather Credential and IP Address Information](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#gather)
   and [SSH into Ops Manager](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#ssh) of
   <em>Advanced Troubleshooting with the BOSH CLI</em> to SSH into the Ops Manager VM.
1. From the Ops Manager VM, log in to your BOSH Director with the BOSH CLI v2.
   See [Log in to the BOSH Director](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#log-in) in
   <em>Advanced Troubleshooting with the BOSH CLI</em>.
1. Use the BOSH CLI v2 to run the `inspect` errand with the following command:
  <pre><code>bosh2 -d service-instance\_GUID run-errand inspect</code></pre>
  <br>
  Where `GUID` is the GUID of the leader-follower service instance retrieved above.
  <br><br>
  For example:
  <pre class="terminal">
  $ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 \
      run-errand inspect
  </pre>
1. Examine the output and locate the information about the leader-follower MySQL VMs:
  <pre class="terminal">
  Instance   mysql/37e4b6bc-2ed6-4bd2-84d1-e59a91f5e7f8
  Exit Code  0
  Stdout     -
  Stderr     2017/12/13 22:26:56 Started executing command: inspect
             2017/12/13 22:26:56 Started GET http<span>s:</span>//127.0.0.1:8443/status
             2017/12/13 22:26:56
             Has Data: true
             Read Only: true
             GTID Executed: 524c4be4-d540-11e7-a1d2-42010a000805:1-85297
             Replication Configured: true
  Instance   mysql/ca0ed8b5-7590-4cde-bba8-7ca2935f2bd0
  Exit Code  0
  Stdout     -
  Stderr     2017/12/13 22:26:56 Started executing command: inspect
             2017/12/13 22:26:56 Started GET http<span>s:</span>//127.0.0.1:8443/status
             2017/12/13 22:26:57
             Has Data: true
             Read Only: false
             GTID Executed: 524c4be4-d540-11e7-a1d2-42010a000805:1-85298
             Replication Configured: false
  </pre>
1. Identify the instance marked `Read Only: false`.
   This is the leader VM.
   Record the index, which is the value for `Instance` after `mysql/`.
   In the above output, the index of the leader VM is `ca0ed8b5-7590-4cde-bba8-7ca2935f2bd0`.
1. Record the index of the other instance, which is the follower VM.
   In the above output, the index of the follower VM is `37e4b6bc-2ed6-4bd2-84d1-e59a91f5e7f8`.
1. Use the BOSH CLI v2 to determine if the leader VM is in the AZ you want to take offline.
   For example:
   <pre class="terminal">$ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 instances</pre>
   Examine the output to determine if the leader VM you identified in the previous step is in the AZ you want to take offline. 

#### <a id='promote-2'></a> Promote the Follower

Perform the following steps to stop the leader VM and promote the follower VM to the new leader:

1. Stop any data from being written to the leader VM by setting it to read only.
   Run the following command:
   <pre><code>bosh2 -d service-instance\_GUID run-errand make-read-only --instance=mysql/INDEX</code></pre>
   <br>
   Where:
   <ul><li>`GUID`: This is the GUID of the leader-follower service instance retrieved above.</li>
   <li>`INDEX`: This is the index of the leader VM retrieved above.</li></ul>
   For example:
   <pre class="terminal">
   $ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 \
      run-errand make-read-only \
      --instance=mysql/ca0ed8b5-7590-4cde-bba8-7ca2935f2bd0
   </pre>
1. Stop the leader VM, using the same values as above.
   For example:
   <pre class="terminal">
    $ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 \
      stop mysql/ca0ed8b5-7590-4cde-bba8-7ca2935f2bd0</pre>
1. Set the follower VM as writable, using the index of the follower VM retrieved above.
   For example:
   <pre class="terminal">
    $ bosh2 -d service-instance\_82dc607-710a-404e-b1b8-a7e3ea7ec063 \
      run-errand make-leader \
      --instance=mysql/37e4b6bc-2ed6-4bd2-84d1-e59a91f5e7f8
   </pre>
   If this command returns an error, re-run it until the follower VM has completed applying the transactions. 
1. Unbind the app from the leader-follower service instance.
   Run the following command:
   <pre><code>cf unbind-service APP SERVICE-INSTANCE</code></pre>
   <br>
   Where:
   <ul><li>`APP`: This is the name of the app bound to the leader-follower service instance.</li>
   <li>`SERVICE-INSTANCE`: This is the name of the leader-follower service instance.</li></ul>
   For example:
   <pre class="terminal">
   $ cf unbind-service my-app my-lf-instance
   </pre>
1. Rebind the app to the leader-follower service instance, using the same values as above.
   For example:
   <pre class="terminal">
   $ cf bind-service my-app my-lf-instance
   </pre>
1. Restage the app.
   For example:
   <pre class="terminal">
   $ cf restage my-app
   </pre>

#### <a id='clean-up'></a>Clean Up Former Leader VM

If you still have access to the former leader VM, perform these steps to clean up that VM:

1. Disable resurrection, specifying the same deployment as above.
   For example:
   <pre class="terminal">
    $ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 \
      update-resurrection off</pre>
1. Use the BOSH CLI v2 to retrieve the CID of the failing former leader VM. 
   For example: 
   <pre class="terminal">
    $ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 instances \
      --details 
      --failing
      --column=”VM CID”
      --json
   </pre>
1. Use the BOSH CLI v2 to retrieve the disk CID of the failing former leader VM. 
   For example: 
   <pre class="terminal">
    $ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 instances \
      --details 
      --failing
      --column=”Disk CIDs”
      --json
   </pre>
1. Delete the failing former leader VM. 
   Run the following command:
   <pre><code>bosh2 -d service-instance\_GUID delete-vm vm-CID</code></pre>
   <br>
   Where:
   <ul><li>`GUID`: This is the GUID of the leader-follower service instance retrieved above.</li>
   <li>`CID`: This is the CID of the failing former leader VM retrieved above.</li>
   </ul>
   For example:
   <pre class="terminal">
   $ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 \
      delete-vm i-1db9ede6
   </pre>
1. Delete the disk of the failing former leader VM.
   Run the following commands:
   <pre><code>bosh2 -d service-instance\_GUID delete-disk DISK-CID
   bosh2 -d service-instance\_GUID orphan-disk DISK-CID</code></pre>
   <br>
   Where:
   <ul><li>`GUID`: This is the GUID of the leader-follower service instance retrieved above.</li>
   <li>`DISK-CID`: This is the disk CID of the failing former leader VM retrieved above.</li>
   </ul>
   For example:
   <pre class="terminal">
   $ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 \
      delete-disk b-1db9ede6
   $ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 \
      orphan-disk b-1db9ede6
   </pre>
1. Download the manifest of the leader-follower deployment. For example:
  <pre class="terminal">
    $ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 \
      manifest > mysql-manifest.yml</pre>
1. Redeploy to create the missing VM and disk in a fresh state. For example:
  <pre class="terminal">
    $ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 \
      deploy mysql-manifest.yml</pre>
1. Use the `configure-leader-follower` errand set the former leader VM as a follower, using the same values as above.
   For example:
   <pre class="terminal">
    $ bosh2 -d service-instance\_82ddc607-710a-404e-b1b8-a7e3ea7ec063 \
      run-errand configure-leader-follower \
      --instance=mysql/ca0ed8b5-7590-4cde-bba8-7ca2935f2bd0</pre>
   Replication and high availability are resumed. The deployment should be in its original, working state. You may turn resurrection back on if desired.

#### <a id='synchronous-replication'></a>Enable synchronous replication
In a leader follower configuration, we support synchronous replication in addition to the default asynchronous replication. In synchronous replication, data does not get committed to the leader node, until the follower acknowledges the same commit and can replicate it. This guarantees that if the leader is lost that a redundant copy of the data exists on the follower - this is not guaranteed by asynchronous replication. This has a data integrity advantage over asynchronous replication, but reduces the performance of write operations (depending on latency).

You can read more about this functionality on the [mysql documentation page](https://dev.mysql.com/doc/refman/5.7/en/replication-semisync.html).

To enable on your service instance, toggle the service flag `replication_mode`:
<pre class="terminal">
$ cf update-service my-lf-instance -c '{"replication_mode": "semi-sync"}'
</pre>

To return to default asynchronous replication, toggle the service flag `replication_mode` as follows:
<pre class="terminal">
$ cf update-service my-lf-instance -c '{"replication_mode": "async"}'
</pre>

MySQL synchronous replication will fallback to asynchronous if a follower has not acknowledged a replicated operation within some time.  On service instance with synchronous replication enabled, the amount of time that a leader node with wait for the follower to acknowledge a commit is set to a high timeout - 2<sup>63</sup> milliseconds (approximately 292 million years). This is done so the default behavior synchronous replication is not to fallback to asynchronous. This timeout can be manually overridden to a lower value in milliseconds with the following command:

<pre class="terminal">
$ cf update-service my-lf-instance -c '{"semi_sync_ack_timeout_in_ms": 5000}'
</pre>

<p class="note"><strong>Note</strong>:
When the replication mode timeout is reached, the replication_mode with automatically revert back to 'async' without any user intervention.
</p>

